import numpy as np
import torch
import torch.nn as nn
import torchvision.models
from torchvision import datasets
from torchvision import transforms
from glob import glob
import os
from os.path import split, splitext
from glob import glob
import numpy as np
from torch.utils.data import Dataset, random_split
from torchvision.io import read_image


# Device configuration
device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')

# import os, time, warnings
# os.environ['CUDA_VISIBLE_DEVICES'] = '0,1,2,3'
# device = torch.device('cuda')

import time


# ------------------------------------------------------------------------------
# [1] Preparing the Input and Target data sets

class CustomDataset(Dataset):
    def __init__(self, is_train):

        super(CustomDataset, self).__init__()
        self.is_train = is_train

        if is_train:
            self.input_format = 'png'
            self.input_dir = "/userhome/karimov_k/CME_estimation/data_npy_0.2/train_0.1/"  # /data/train/'

            self.label_path_list = sorted(glob(os.path.join(self.input_dir, '*.' + self.input_format)))

        #             print(len(self.label_path_list))
        else:
            self.input_format = 'png'
            self.input_dir = "/userhome/karimov_k/CME_estimation/data_npy_0.2/test_0.1/"  # data/test/'

            self.label_path_list = sorted(glob(os.path.join(self.input_dir, '*.' + self.input_format)))

    def __len__(self):
        return len(self.label_path_list)

    def __getitem__(self, index):
        list_transforms = []
        list_transforms += []

        if self.is_train:

            # [ Train Input ] =============================================================
            input_data = np.load(self.label_path_list[index])/255.0
            # [ Train Target ] ============================================================

            TAR_H = float(self.label_path_list[index][-18:-13])/27.0
            TAR_PA = float(self.label_path_list[index][-9:-4])/360.0
            target_data = torch.tensor([TAR_H, TAR_PA])




        # [ Test data ] ===============================================================
        else:
            # [ Test Input ] ==============================================================
            input_data = np.load(self.label_path_list[index])/255.0
            TAR_H = float(self.label_path_list[index][-18:-13]) / 27.0
            TAR_PA = float(self.label_path_list[index][-9:-4]) / 360.0
            target_data = torch.tensor([TAR_H, TAR_PA])
            # return input_data

        return input_data, target_data


from torch.utils.data import DataLoader

dataset = CustomDataset(is_train=True)
dataset, valid = random_split(dataset,[5117,1000])
data_loader = DataLoader(dataset, batch_size=64, shuffle=True,
                         num_workers=4)
valid_loader = DataLoader(valid, batch_size=64, shuffle=True,
                         num_workers=4)


class ResidualBlock(nn.Module):
    def __init__(self, in_channels, out_channels, stride=1, downsample=None):
        super(ResidualBlock, self).__init__()
        self.conv1 = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU())
        self.conv2 = nn.Sequential(
            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(out_channels))
        self.downsample = downsample
        self.relu = nn.ReLU()
        self.out_channels = out_channels

    def forward(self, x):
        residual = x
        out = self.conv1(x)
        out = self.conv2(out)
        if self.downsample:
            residual = self.downsample(x)
        out += residual
        out = self.relu(out)
        return out


class ResNet(nn.Module):
    def __init__(self, block, layers, num_classes):
        super(ResNet, self).__init__()
        self.inplanes = 64
        self.conv1 = nn.Sequential(
            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),
            nn.BatchNorm2d(64),
            nn.ReLU())
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
        self.layer0 = self._make_layer(block, 64, layers[0], stride=1)
        self.layer1 = self._make_layer(block, 128, layers[1], stride=2)
        self.layer2 = self._make_layer(block, 256, layers[2], stride=2)
        self.layer3 = self._make_layer(block, 512, layers[3], stride=2)
        self.avgpool = nn.AvgPool2d(7, stride=1)
        self.fc = nn.Linear(512, num_classes)

    def _make_layer(self, block, planes, blocks, stride=1):
        downsample = None
        if stride != 1 or self.inplanes != planes:
            downsample = nn.Sequential(
                nn.Conv2d(self.inplanes, planes, kernel_size=1, stride=stride),
                nn.BatchNorm2d(planes),
            )
        layers = []
        layers.append(block(self.inplanes, planes, stride, downsample))
        self.inplanes = planes
        for i in range(1, blocks):
            layers.append(block(self.inplanes, planes))

        return nn.Sequential(*layers)

    def forward(self, x):
        x = self.conv1(x)
        x = self.maxpool(x)
        x = self.layer0(x)
        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)

        x = self.avgpool(x)
        x = x.view(x.size(0), -1)
        x = self.fc(x)

        return x

num_classes = 1
num_epochs = 500
save_interval = 20
batch_size = 16
learning_rate = 0.0001


model = ResNet(ResidualBlock, [3, 4, 6, 3], num_classes=num_classes).to(device)
model = model.to(device)
# model = torchvision.models.resnet50()
# model = ResNet(ResidualBlock, [3, 4, 6, 3])
#
# model = nn.DataParallel(model)
#
# from torchsummary import summary
# summary(model, (3, 224, 224))





# Loss and optimizer
#     criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)

# Train the model
total_step = data_loader


import gc

total_step = data_loader  # len(data_loader)

save_path = "/userhome/karimov_k/CME_estimation/Model_0.4/res_pa_0.1/"
if not(os.path.exists(save_path) and os.path.isdir(save_path)):
    os.mkdir(save_path)

loss_res=[]
loss_r=[]
loss_val=[]

min_valid_loss = np.inf
min_val_epoch = 0

for epoch in range(num_epochs):

    t0 = time.time()

    for i, (images, labels) in enumerate(data_loader):
        # Move tensors to the configured device
        images = images.to(torch.float)
        images = images.to(device)
        labels = labels.to(device)
        labels = labels.to(torch.float)

        labels = labels[:,1]
        # print(labels)

        # Forward pass
        outputs = model(images)
        # print(len(outputs))

        def new_loss(outputs, labels):
            # x = torch.mean(((outputs*360) - (labels*360)))
            x = outputs*360 - labels*360
            torch.where(x<180,x,360-x)
            torch.where(x>-180,x,360+x)
            # torch.where(x > 180, x,x)
            # if x > 180:
            #     loss = 360-x
            # elif x < -180:
            #     loss = 360+x
            # else:
            #     loss = x
            loss = torch.mean(x**2) #(outputs - labels))
            return torch.sqrt(loss)

        # criterion_mse = nn.MSELoss()
        train_loss = new_loss(outputs.to(device), labels)

        # Backward and optimize
        optimizer.zero_grad()
        train_loss.backward()
        optimizer.step()

        if epoch % save_interval == 0:

            torch.save(model.state_dict(), os.path.join(save_path, 'epoch-{:03d}.pt'.format(epoch)))
    print(f'## Epoch {epoch+1}##')
    print('Train loss: ', train_loss.item())
    print('Prediction : ', outputs[0] * 360, '\n', 'Target : ', labels[0] * 360)

    for i, (images, labels) in enumerate(valid_loader):
        # Move tensors to the configured device
        images = images.to(torch.float)
        images = images.to(device)
        labels = labels.to(device)
        labels = labels.to(torch.float)

        labels = labels[:, 1]
        # print(labels)

        # Forward pass
        outputs = model(images)


        # def new_loss(outputs, labels):
        #     # x = torch.mean(((outputs*360) - (labels*360)))
        #     x = outputs*360 - labels*360
        #     torch.where(x < 180, x, 360 - x)
        #     torch.where(x > -180, x, 360 + x)
        #     # torch.where(x > 180, x, x)
        #
        #     loss = torch.mean(x**2)#(outputs - labels))
        #     return torch.sqrt(loss)

        val_loss = new_loss(outputs.to(device), labels).item()




    if min_valid_loss >val_loss:
        # print(f'Validation Loss Decreased({min_valid_loss:.6f}--->{valid_loss:.6f})\t\t Validation Loss: {valid_loss /len(valid_loader)}')
        min_valid_loss = val_loss
        min_val_epoch = epoch


    print('Prediction val : ', outputs[0]*360,'\n', 'Target val : ', labels[0]*360)
    loss_r.append((epoch, train_loss.item()))
    loss_val.append((epoch, val_loss))
    print('Validation Loss: {:.4f}'.format(val_loss))
    print('time:{}'.format((time.time() - t0)))
    print('\n')

loss_r = np.array(loss_r)
np.save('/userhome/karimov_k/CME_estimation/LOSS_res/train_loss/loss_train_pa_0.1.npy', loss_r)
loss_val = np.array(loss_val)
np.save('/userhome/karimov_k/CME_estimation/LOSS_res/val_loss/loss_val_pa_0.1.npy', loss_val)


